SecondMind - AI-Driven Idea Generator
Project Introduction
SecondMind is an advanced AI-driven autonomous agent framework designed to enhance research, knowledge synthesis, and decision-making. This project integrates multiple intelligent agents, each with a specialized function, working collaboratively to analyze, refine, and evaluate generated hypotheses.
The system leverages Large Language Models (LLMs) like Gemini, along with Natural Language Processing (NLP), Machine Learning (ML), and web scraping techniques to collect and process information from diverse sources such as research papers, patents, and news articles.
With a modular and scalable architecture, SecondMind enables real-time insights by:
â€¢	Generating hypotheses based on retrieved knowledge.
â€¢	Reflecting on and ranking outputs for coherence and credibility.
â€¢	Evolving ideas through iterative improvements.
â€¢	Providing historical context using previous interactions.
â€¢	Automating web research using APIs and scrapers.
The system can be extended to various domains, including academic research, market analysis, and innovation tracking. Its agentic framework allows it to adapt and learn over time, ensuring high-quality outputs with minimal human intervention.
 Features
â€¢	AI-generated text based on prompts
â€¢	Reflection and evaluation to improve outputs
â€¢	FastAPI-powered REST API
â€¢	Modular agent-based architecture
â€¢	Logging and storage support

Project Goals
The primary goal of SecondMind is to create an autonomous, intelligent research and decision-support system that can:
âœ… Automate Research: Collect and process data from various sources, including academic papers, patents, and news articles.
âœ… Generate Insights: Utilize LLMs to synthesize and summarize information into meaningful insights.
âœ… Validate and Refine Information: Use agent-based ranking, reflection, and evolution mechanisms to improve content accuracy and coherence.
âœ… Enhance Decision-Making: Assist users in making informed decisions by presenting well-structured, context-aware recommendations.
âœ… Ensure Scalability & Adaptability: Implement a modular design that allows integration with new tools, APIs, and custom workflows.
 Project Structure
second_mind/
â”œâ”€â”€ main.py                     # Entry point
â”œâ”€â”€ config.py                   # Configuration and settings
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ README.md                   # Documentation
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ _init_.py
â”‚   â”œâ”€â”€ supervisor.py           # Supervisor agent implementation
â”‚   â”œâ”€â”€ storage.py              # Memory storage system
â”‚   â””â”€â”€ context_manager.py      # Context protocol server
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ _init_.py
â”‚   â”œâ”€â”€ base_agent.py           # Abstract base agent class
â”‚   â”œâ”€â”€ generation_agent.py     # Creates initial hypotheses
â”‚   â”œâ”€â”€ reflection_agent.py     # Checks coherence
â”‚   â”œâ”€â”€ ranking_agent.py        # Scores outputs
â”‚   â”œâ”€â”€ evolution_agent.py      # Refines ideas
â”‚   â”œâ”€â”€ proximity_agent.py      # Links to past interactions
â”‚   â””â”€â”€ meta_review_agent.py    # Evaluates process
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ _init_.py
â”‚   â”œâ”€â”€ google_search_wrapper.py# Google Search API integration
â”‚   â”œâ”€â”€ scraper.py              # Web scraping utilities
â”‚   â”œâ”€â”€ academic_scraper.py     # Academic repository scraper
â”‚   â”œâ”€â”€ patent_scraper.py       # Patent database scraper
â”‚   â””â”€â”€ news_scraper.py         # Tech news scraper
â””â”€â”€ utils/
    â”œâ”€â”€ _init_.py
    â”œâ”€â”€ logger.py               # Logging utilities



# **ğŸ§  Second Mind**  
**An AI-driven system that mimics human learning through specialized agents.**  

## **ğŸ›  Installation & Setup**  

### **1ï¸âƒ£ Clone the Repository**  
```bash
git clone https://github.com/SkandaGanesha1/Second_Mind_Project.git
```

### **2ï¸âƒ£ Install Dependencies**  
Ensure you have Python 3.9+ installed, then run:  
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Set Up API Keys**  
Create a `.env` file in the project root and add:  
```plaintext
GEMINI_API_KEY=your-gemini-api-key
```

---

## **ğŸš€ Usage**  

### **ğŸ¯ Running the Core System**  
To generate AI-powered ideas, execute:  
```bash
python main.py
```

### **ğŸŒ Running the API**  
Start the API server using FastAPI:  
```bash
uvicorn web.api:app --reload
```
Test the API using:  
```bash
curl -X POST "http://127.0.0.1:8000/generate" -d "prompt=AI use case"
```

---

## **ğŸ“¡ API Endpoints**  

| Method | Endpoint  | Description                  |
|--------|----------|------------------------------|
| **POST** | `/generate` | Generates AI-based responses |

---

## **ğŸ›  Technologies Used**  
- **Python 3.9+**  
- **Google Gemini AI** (for text generation)  
- **FastAPI** (for API development)  
- **Logging & Storage** (JSON-based)  

---

## **ğŸš€ Future Enhancements**  
âœ… **Add more specialized agents** (Ranking, Evolution, etc.)  
âœ… **Enhance storage** with SQLite or Redis  
âœ… **Deploy API** using Docker & Cloud  
âœ… **Integrate a web-based UI**  

---

## **ğŸ‘¥ Contributors**  
ğŸ‘¨â€ğŸ’» **Vikranth S H** - [GitHub Profile]([https://github.com/VikranthSH))  
ğŸ“§ **Contact:** vikranthsh83@gmail.com  

![Screenshot 2025-03-20 150335](https://github.com/user-attachments/assets/10ed83b2-e5b5-4dc2-9d84-d7cb69a4014f)


